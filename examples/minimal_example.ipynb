{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Minimal Example\n",
    "\n",
    "Most of the functionality of this package is bundled in two main classes: ESN\n",
    "and ESNWrapper. (ESN stands for Echo State Network.)\n",
    "For all normal usage of the scan package, ESNWrapper is the\n",
    "class to use.\n",
    "\n",
    "As always, we first want to import the needed packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As with most machine learning techniques, we need some training data, which we\n",
    "generate here artificially by simulating the chaotic Lorenz63 system for 5000\n",
    "time steps.\n",
    "\n",
    "The starting point is chosen to be on the chaotic attractor we want to predict,\n",
    "so that we don't use any transient dynamics as training data.  \n",
    "Then we call the simulate_trajectory() function to simulate the Lorenz63 system.  \n",
    "For more details on the simulation of systems, please see the \n",
    "simulations_example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "starting_point = np.array([-14.03020521, -20.88693127, 25.53545])\n",
    "sim_data = scan.simulations.Lorenz63(dt=2e-2).simulate(time_steps=10000, starting_point=starting_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a convention, the data specified is always input data in a np.ndarray of\n",
    "the shape (t, d), where t is the number of time steps and d the system\n",
    "dimension\n",
    "I.g. RC works for any number of dimensions and data length.\n",
    "\n",
    "Until now, the esn object is basically empty. One main component of reservoir\n",
    "computing is the reservoir, i.e. the internal network, wich we can create via\n",
    "create_network()."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we can create an instance of the ESNWrapper class to be used throughout\n",
    "this example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "esn = scan.ESNWrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can create the network.\n",
    "\n",
    "For the sake of consistency, we want to set the random seed used to create the\n",
    "random network, n_seed, so that we always create the same network, and hence the same\n",
    "prediction, when running this example.\n",
    "\n",
    "Note that the entirety of the scan package is independent of any global seed you might\n",
    "have set elsewhere via e.g. np.random.seed()."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "esn.create_network(n_seed=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A typical and natural way to use an ESN is to first synchronize on one section \n",
    "of a trajectory, train on the next and then start the prediction on the\n",
    "subsequent data.  \n",
    "The method train_and_predict() does exactly that.\n",
    "\n",
    "The number of time steps used to synchronize the reservoir should be at least\n",
    "a couple hundred but no more than a couple thousand are needed, even for\n",
    "complex systems."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sync_steps = 400"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of time steps used to train the reservoir, depends hugely on\n",
    "the system in question. More is usually better, of course, but for simple\n",
    "systems even a couple hundred time steps may lead to a successful training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_steps = 5000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of time steps to be predicted:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_steps = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plug it all in:\n",
    "\n",
    "Note that we also set the seed w_in_seed of the randomly created input matrix w_n here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred, y_test = esn.train_and_predict(\n",
    "    x_data=sim_data, train_sync_steps=train_sync_steps, train_steps=train_steps, pred_steps=pred_steps, w_in_seed=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first output y_pred is the predicted trajectory\n",
    "print(y_pred.shape)\n",
    "\n",
    "If the input data is longer than the data used for synchronization and\n",
    "training, i.e. if\n",
    "\n",
    "> x_data.shape[0] > train_sync_steps + train_steps,\n",
    "\n",
    "then the rest of the data can be used as test set to compare the prediction\n",
    "against. If the prediction where perfect y_pred and y_test would be the same\n",
    "Be careful though, if\n",
    "\n",
    "> x_data.shape[0] - (train_sync_steps + train_steps) < pred_steps\n",
    "  \n",
    "then the test data set is shorter than the predicted one:\n",
    "\n",
    "> y_test.shape[0] < y_pred.shape[0].\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot prediction and simulation to compare them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(9, 6), dpi=300)\n",
    "ax1 = fig1.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "ax1.plot(y_test[:, 0], y_test[:, 1], y_test[:, 2], alpha=0.8, color=\"blue\", label=\"simulation\")\n",
    "ax1.plot(y_pred[:, 0], y_pred[:, 1], y_pred[:, 2], alpha=0.8, color=\"orange\", label=\"prediction\")\n",
    "\n",
    "start = y_pred[0]\n",
    "ax1.plot([start[0]], [start[1]], [start[2]], color=\"black\", linestyle=\"\", marker=\"o\", label=\"starting point\")\n",
    "\n",
    "ax1.set_title(\"Simulation vs Prediction\")\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_zlabel(\"z\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, both the prediction (orange) and the simulated data the \n",
    "prediction is based on (blue) show the same qualitative behavior of the Lorenz \n",
    "attractor.  \n",
    "Qualitatively, the prediction of the Lorenz system was a success."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, plot their x coordinates for a more detailed comparison."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(9, 6), dpi=300)\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "ax2.plot(y_test[:, 0], color=\"blue\", label=\"simulation\")\n",
    "ax2.plot(y_pred[:, 0], color=\"orange\", linestyle=\"--\", label=\"prediction\")\n",
    "\n",
    "start = y_pred[0]\n",
    "ax2.plot(start[0], color=\"black\", linestyle=\"\", marker=\"o\", label=\"starting point\")\n",
    "\n",
    "ax2.set_title(\"X-Coordinates of Simulation and Prediction\")\n",
    "ax2.set_xlabel(\"time steps\")\n",
    "ax2.set_ylabel(\"x\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see prediction and data staying very close together in the beginning, drifting apart slowly and after some\n",
    "time the trajectories diverge completely. Notably though the RC prediction still exhibit the same \"climate\" as the\n",
    "original system, i.e. they are qualitatively still the same even after their trajectories diverged.\n",
    "\n",
    "If your RC prediction is working, this kind of prediction behavior can be seen for a wide variety of chaotic systems."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}