### Some Reservoir Computing Literature  

For a comparison between different RNN methods and RC, as well as a demonstration of RC's predictive power and speed:  
*Chattopadhyay, A.; Hassanzadeh, P.; Palem, K.; Subramanian, D. Data-Driven Prediction of a Multi-Scale Lorenz 96 Chaotic System Using a Hierarchy of Deep Learning Methods: Reservoir Computing, ANN, and RNN-LSTM. 2019, 1–21.*

For a quick introduction:  
*Haluszczynski, A.; Räth, C. Good and Bad Predictions: Assessing and Improving the Replication of Chaotic Attractors by Means of Reservoir Computing. Chaos 2019, 29.*  
It explains the basic math quite well and applies RC to the canonical Lorenz system. Furthermore, it discusses possibly the biggest distinguishing feature of RC, the static randomness of it's network and the resulting consequences, which is very important to understand when working with RC.

For some "classical" RC literature, the paper(s) by Jaeger et. al.:  
*Lukoševičius, M.; Jaeger, H. Reservoir Computing Approaches to Recurrent Neural Network Training. Comput. Sci. Rev. 2009, 3, 127–149.*  
It discusses the basics and the many possible variations of RC in addition to its development history. This paper is of course not quite up to date anymore, as it's 10 years old by now, but the qualitative results and ideas still hold true today.
